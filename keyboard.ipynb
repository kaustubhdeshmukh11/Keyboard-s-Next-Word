{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "faqs= \"\"\"Good morning have a great day\n",
        "Good morning hope you are well\n",
        "Good night sweet dreams take care\n",
        "Good night sleep well see you\n",
        "Happy birthday have a wonderful day\n",
        "Happy birthday may all your wishes\n",
        "Happy new year wish you success\n",
        "Happy anniversary wishing you lots of love\n",
        "I love you so much baby\n",
        "I love you more than anything\n",
        "I miss you so much right now\n",
        "I miss you can't wait to see\n",
        "See you soon take care stay safe\n",
        "See you later have a nice day\n",
        "How are you doing today\n",
        "How are you feeling now\n",
        "What are you doing today\n",
        "What are you up to now\n",
        "Where are you right now\n",
        "Where are you going today\n",
        "Thank you so much for your help\n",
        "Thank you very much have a nice day\n",
        "Thanks a lot I appreciate it\n",
        "I am going to the market\n",
        "I am going to the gym\n",
        "I am going to bed now\n",
        "I am feeling tired and sleepy\n",
        "I am feeling happy and grateful\n",
        "I am really excited about tomorrow\n",
        "Let me know when you are free\n",
        "Let me know if you need help\n",
        "Let me know what you think\n",
        "Can we meet tomorrow at the cafe\n",
        "Can we talk later today\n",
        "Can you please help me\n",
        "Can you send me the file\n",
        "Do you want to go out\n",
        "Do you want to eat something\n",
        "Don't forget to drink water\n",
        "Don't forget to take your medicine\n",
        "I hope you are doing well\n",
        "I hope everything goes well\n",
        "I hope you have a good time\n",
        "It's a beautiful day outside\n",
        "It's going to be okay\n",
        "It's time to go now\n",
        "It's time for dinner\n",
        "I need your help right now\n",
        "I need to talk to you\n",
        "I need to finish my work\n",
        "What time are you coming\n",
        "What time should we meet\n",
        "I'm waiting for your reply\n",
        "I'm looking forward to seeing you\n",
        "I'm at the station right now\n",
        "I'm on my way home\n",
        "Are you coming to the party\n",
        "Are you free this weekend\n",
        "Are you feeling okay today\n",
        "I will call you later\n",
        "I will talk to you soon\n",
        "I will see you tomorrow\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "J1D42emD32Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "KhtDxwL_AXFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "K8MRFre9AaG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrpAl3EDAgvh",
        "outputId": "df31f376-312e-4548-8ddc-519425dc609d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "44VahqKdAjr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqwPDzNA5mR",
        "outputId": "be75075e-085e-4045-a1fe-74121ce7df3d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11, 4],\n",
              " [11, 4, 100],\n",
              " [11, 4, 100, 101],\n",
              " [11, 4, 100, 101, 2],\n",
              " [11, 4, 100, 101, 2, 102],\n",
              " [11, 4, 100, 101, 2, 102, 13],\n",
              " [11, 4, 100, 101, 2, 102, 13, 103],\n",
              " [11, 4, 100, 101, 2, 102, 13, 103, 104],\n",
              " [1, 4],\n",
              " [1, 4, 12],\n",
              " [1, 4, 12, 23],\n",
              " [1, 4, 12, 23, 2],\n",
              " [1, 4, 12, 23, 2, 105],\n",
              " [1, 4, 12, 23, 2, 105, 7],\n",
              " [1, 4, 12, 23, 2, 105, 7, 24],\n",
              " [1, 4, 12, 23, 2, 105, 7, 24, 1],\n",
              " [1, 4, 12, 23, 2, 105, 7, 24, 1, 14],\n",
              " [1, 15],\n",
              " [1, 15, 43],\n",
              " [1, 15, 43, 106],\n",
              " [1, 15, 43, 106, 44],\n",
              " [1, 15, 43, 106, 44, 9],\n",
              " [1, 15, 43, 106, 44, 9, 25],\n",
              " [1, 15, 43, 106, 44, 9, 25, 107],\n",
              " [108, 109],\n",
              " [108, 109, 45],\n",
              " [108, 109, 45, 3],\n",
              " [108, 109, 45, 3, 46],\n",
              " [108, 109, 45, 3, 46, 110],\n",
              " [108, 109, 45, 3, 46, 110, 1],\n",
              " [108, 109, 45, 3, 46, 110, 1, 4],\n",
              " [108, 109, 45, 3, 46, 110, 1, 4, 9],\n",
              " [108, 109, 45, 3, 46, 110, 1, 4, 9, 47],\n",
              " [1, 26],\n",
              " [1, 26, 43],\n",
              " [1, 26, 43, 111],\n",
              " [1, 26, 43, 111, 2],\n",
              " [1, 26, 43, 111, 2, 112],\n",
              " [1, 26, 43, 111, 2, 112, 48],\n",
              " [1, 26, 43, 111, 2, 112, 48, 27],\n",
              " [1, 26, 43, 111, 2, 112, 48, 27, 49],\n",
              " [11, 16],\n",
              " [11, 16, 17],\n",
              " [11, 16, 17, 2],\n",
              " [11, 16, 17, 2, 50],\n",
              " [11, 16, 17, 2, 50, 3],\n",
              " [11, 16, 17, 2, 50, 3, 113],\n",
              " [11, 16, 17, 2, 50, 3, 113, 7],\n",
              " [11, 16, 17, 2, 50, 3, 113, 7, 27],\n",
              " [11, 16, 17, 2, 50, 3, 113, 7, 27, 114],\n",
              " [1, 115],\n",
              " [1, 115, 18],\n",
              " [1, 115, 18, 19],\n",
              " [1, 115, 18, 19, 3],\n",
              " [1, 115, 18, 19, 3, 51],\n",
              " [1, 115, 18, 19, 3, 51, 2],\n",
              " [1, 115, 18, 19, 3, 51, 2, 116],\n",
              " [1, 115, 18, 19, 3, 51, 2, 116, 52],\n",
              " [1, 115, 18, 19, 3, 51, 2, 116, 52, 117],\n",
              " [1, 53],\n",
              " [1, 53, 28],\n",
              " [1, 53, 28, 5],\n",
              " [1, 53, 28, 5, 9],\n",
              " [1, 53, 28, 5, 9, 118],\n",
              " [1, 53, 28, 5, 9, 118, 2],\n",
              " [1, 53, 28, 5, 9, 118, 2, 54],\n",
              " [1, 53, 28, 5, 9, 118, 2, 54, 3],\n",
              " [1, 53, 28, 5, 9, 118, 2, 54, 3, 29],\n",
              " [1, 53, 28, 5, 9, 118, 2, 54, 3, 29, 7],\n",
              " [1, 53, 28, 5, 9, 118, 2, 54, 3, 29, 7, 55],\n",
              " [1, 53, 28, 5, 9, 118, 2, 54, 3, 29, 7, 55, 56],\n",
              " [1, 53, 28, 5, 9, 118, 2, 54, 3, 29, 7, 55, 56, 57],\n",
              " [11, 4],\n",
              " [11, 4, 119],\n",
              " [11, 4, 119, 2],\n",
              " [11, 4, 119, 2, 12],\n",
              " [11, 4, 119, 2, 12, 14],\n",
              " [11, 4, 119, 2, 12, 14, 3],\n",
              " [11, 4, 119, 2, 12, 14, 3, 120],\n",
              " [11, 4, 119, 2, 12, 14, 3, 120, 121],\n",
              " [1, 58],\n",
              " [1, 58, 30],\n",
              " [1, 58, 30, 122],\n",
              " [1, 58, 30, 122, 7],\n",
              " [1, 58, 30, 122, 7, 59],\n",
              " [1, 58, 30, 122, 7, 59, 60],\n",
              " [1, 58, 30, 122, 7, 59, 60, 2],\n",
              " [1, 58, 30, 122, 7, 59, 60, 2, 123],\n",
              " [1, 58, 30, 122, 7, 59, 60, 2, 123, 61],\n",
              " [3, 124],\n",
              " [3, 124, 4],\n",
              " [3, 124, 4, 19],\n",
              " [3, 124, 4, 19, 125],\n",
              " [3, 124, 4, 19, 125, 126],\n",
              " [3, 124, 4, 19, 125, 126, 127],\n",
              " [3, 124, 4, 19, 125, 126, 127, 128],\n",
              " [3, 124, 4, 19, 125, 126, 127, 128, 4],\n",
              " [3, 124, 4, 19, 125, 126, 127, 128, 4, 9],\n",
              " [3, 124, 4, 19, 125, 126, 127, 128, 4, 9, 129],\n",
              " [3, 124, 4, 19, 125, 126, 127, 128, 4, 9, 129, 49],\n",
              " [3, 124, 4, 19, 125, 126, 127, 128, 4, 9, 129, 49, 10],\n",
              " [3, 124, 4, 19, 125, 126, 127, 128, 4, 9, 129, 49, 10, 5],\n",
              " [1, 130],\n",
              " [1, 130, 131],\n",
              " [1, 130, 131, 62],\n",
              " [1, 130, 131, 62, 132],\n",
              " [1, 130, 131, 62, 132, 133],\n",
              " [1, 130, 131, 62, 132, 133, 7],\n",
              " [1, 130, 131, 62, 132, 133, 7, 134],\n",
              " [1, 130, 131, 62, 132, 133, 7, 134, 6],\n",
              " [1, 130, 131, 62, 132, 133, 7, 134, 6, 135],\n",
              " [1, 130, 131, 62, 132, 133, 7, 134, 6, 135, 136],\n",
              " [1, 137],\n",
              " [1, 137, 62],\n",
              " [1, 137, 62, 63],\n",
              " [1, 137, 62, 63, 9],\n",
              " [1, 137, 62, 63, 9, 138],\n",
              " [1, 137, 62, 63, 9, 138, 31],\n",
              " [1, 137, 62, 63, 9, 138, 31, 20],\n",
              " [1, 137, 62, 63, 9, 138, 31, 20, 3],\n",
              " [1, 137, 62, 63, 9, 138, 31, 20, 3, 139],\n",
              " [1, 137, 62, 63, 9, 138, 31, 20, 3, 139, 140],\n",
              " [1, 137, 62, 63, 9, 138, 31, 20, 3, 139, 140, 64],\n",
              " [11, 4],\n",
              " [11, 4, 141],\n",
              " [11, 4, 141, 2],\n",
              " [11, 4, 141, 2, 15],\n",
              " [11, 4, 141, 2, 15, 142],\n",
              " [11, 4, 141, 2, 15, 142, 32],\n",
              " [11, 4, 141, 2, 15, 142, 32, 143],\n",
              " [1, 26],\n",
              " [1, 26, 144],\n",
              " [1, 26, 144, 145],\n",
              " [1, 26, 144, 145, 146],\n",
              " [1, 26, 144, 145, 146, 147],\n",
              " [1, 26, 144, 145, 146, 147, 6],\n",
              " [1, 26, 144, 145, 146, 147, 6, 148],\n",
              " [1, 26, 144, 145, 146, 147, 6, 148, 2],\n",
              " [1, 26, 144, 145, 146, 147, 6, 148, 2, 149],\n",
              " [1, 150],\n",
              " [1, 150, 151],\n",
              " [1, 150, 151, 152],\n",
              " [1, 150, 151, 152, 10],\n",
              " [1, 150, 151, 152, 10, 153],\n",
              " [1, 150, 151, 152, 10, 153, 154],\n",
              " [1, 150, 151, 152, 10, 153, 154, 2],\n",
              " [1, 150, 151, 152, 10, 153, 154, 2, 155],\n",
              " [3, 156],\n",
              " [3, 156, 157],\n",
              " [3, 156, 157, 4],\n",
              " [3, 156, 157, 4, 31],\n",
              " [3, 156, 157, 4, 31, 20],\n",
              " [3, 156, 157, 4, 31, 20, 3],\n",
              " [3, 156, 157, 4, 31, 20, 3, 46],\n",
              " [3, 156, 157, 4, 31, 20, 3, 46, 158],\n",
              " [3, 156, 157, 4, 31, 20, 3, 46, 158, 159],\n",
              " [1, 12],\n",
              " [1, 12, 160],\n",
              " [1, 12, 160, 65],\n",
              " [1, 12, 160, 65, 161],\n",
              " [1, 12, 160, 65, 161, 2],\n",
              " [1, 12, 160, 65, 161, 2, 14],\n",
              " [1, 12, 160, 65, 161, 2, 14, 18],\n",
              " [1, 12, 160, 65, 161, 2, 14, 18, 7],\n",
              " [1, 12, 160, 65, 161, 2, 14, 18, 7, 3],\n",
              " [1, 12, 160, 65, 161, 2, 14, 18, 7, 3, 51],\n",
              " [11, 4],\n",
              " [11, 4, 162],\n",
              " [11, 4, 162, 2],\n",
              " [11, 4, 162, 2, 33],\n",
              " [11, 4, 162, 2, 33, 163],\n",
              " [11, 4, 162, 2, 33, 163, 66],\n",
              " [1, 15],\n",
              " [1, 15, 164],\n",
              " [1, 15, 164, 8],\n",
              " [1, 15, 164, 8, 5],\n",
              " [1, 15, 164, 8, 5, 2],\n",
              " [1, 15, 164, 8, 5, 2, 165],\n",
              " [1, 15, 164, 8, 5, 2, 165, 67],\n",
              " [1, 15, 164, 8, 5, 2, 165, 67, 7],\n",
              " [1, 15, 164, 8, 5, 2, 165, 67, 7, 34],\n",
              " [1, 15, 164, 8, 5, 2, 165, 67, 7, 34, 166],\n",
              " [1, 167],\n",
              " [1, 167, 5],\n",
              " [1, 167, 5, 6],\n",
              " [1, 167, 5, 6, 68],\n",
              " [1, 167, 5, 6, 68, 168],\n",
              " [1, 167, 5, 6, 68, 168, 69],\n",
              " [1, 167, 5, 6, 68, 168, 69, 169],\n",
              " [1, 167, 5, 6, 68, 168, 69, 169, 3],\n",
              " [1, 167, 5, 6, 68, 168, 69, 169, 3, 29],\n",
              " [1, 4],\n",
              " [1, 4, 35],\n",
              " [1, 4, 35, 2],\n",
              " [1, 4, 35, 2, 70],\n",
              " [1, 4, 35, 2, 70, 3],\n",
              " [1, 4, 35, 2, 70, 3, 170],\n",
              " [1, 4, 35, 2, 70, 3, 170, 2],\n",
              " [1, 4, 35, 2, 70, 3, 170, 2, 71],\n",
              " [1, 4, 35, 2, 70, 3, 170, 2, 71, 7],\n",
              " [1, 4, 35, 2, 70, 3, 170, 2, 71, 7, 17],\n",
              " [1, 4, 35, 2, 70, 3, 170, 2, 71, 7, 17, 72],\n",
              " [1, 171],\n",
              " [1, 171, 172],\n",
              " [1, 171, 172, 9],\n",
              " [1, 171, 172, 9, 173],\n",
              " [1, 171, 172, 9, 173, 174],\n",
              " [1, 171, 172, 9, 173, 174, 175],\n",
              " [1, 171, 172, 9, 173, 174, 175, 176],\n",
              " [1, 171, 172, 9, 173, 174, 175, 176, 3],\n",
              " [1, 171, 172, 9, 173, 174, 175, 176, 3, 177],\n",
              " [1, 171, 172, 9, 173, 174, 175, 176, 3, 177, 178],\n",
              " [1, 179],\n",
              " [1, 179, 5],\n",
              " [1, 179, 5, 8],\n",
              " [1, 179, 5, 8, 180],\n",
              " [1, 179, 5, 8, 180, 13],\n",
              " [1, 179, 5, 8, 180, 13, 36],\n",
              " [1, 179, 5, 8, 180, 13, 36, 2],\n",
              " [1, 179, 5, 8, 180, 13, 36, 2, 12],\n",
              " [1, 179, 5, 8, 180, 13, 36, 2, 12, 70],\n",
              " [1, 179, 5, 8, 180, 13, 36, 2, 12, 70, 5],\n",
              " [1, 181],\n",
              " [1, 181, 182],\n",
              " [1, 181, 182, 6],\n",
              " [1, 181, 182, 6, 183],\n",
              " [1, 181, 182, 6, 183, 2],\n",
              " [1, 181, 182, 6, 183, 2, 184],\n",
              " [1, 185],\n",
              " [1, 185, 3],\n",
              " [1, 185, 3, 37],\n",
              " [1, 185, 3, 37, 186],\n",
              " [1, 185, 3, 37, 186, 73],\n",
              " [1, 185, 3, 37, 186, 73, 7],\n",
              " [1, 185, 3, 37, 186, 73, 7, 187],\n",
              " [11, 4],\n",
              " [11, 4, 74],\n",
              " [11, 4, 74, 188],\n",
              " [11, 4, 74, 188, 2],\n",
              " [11, 4, 74, 188, 2, 189],\n",
              " [11, 4, 74, 188, 2, 189, 3],\n",
              " [11, 4, 74, 188, 2, 189, 3, 37],\n",
              " [11, 4, 74, 188, 2, 189, 3, 37, 18],\n",
              " [1, 190],\n",
              " [1, 190, 191],\n",
              " [1, 190, 191, 5],\n",
              " [1, 190, 191, 5, 38],\n",
              " [1, 190, 191, 5, 38, 75],\n",
              " [1, 190, 191, 5, 38, 75, 192],\n",
              " [1, 190, 191, 5, 38, 75, 192, 193],\n",
              " [1, 194],\n",
              " [1, 194, 9],\n",
              " [1, 194, 9, 195],\n",
              " [1, 194, 9, 195, 76],\n",
              " [1, 194, 9, 195, 76, 2],\n",
              " [1, 194, 9, 195, 76, 2, 196],\n",
              " [1, 194, 9, 195, 76, 2, 196, 77],\n",
              " [1, 194, 9, 195, 76, 2, 196, 77, 10],\n",
              " [1, 194, 9, 195, 76, 2, 196, 77, 10, 197],\n",
              " [1, 198],\n",
              " [1, 198, 65],\n",
              " [1, 198, 65, 199],\n",
              " [1, 198, 65, 199, 10],\n",
              " [1, 198, 65, 199, 10, 3],\n",
              " [1, 198, 65, 199, 10, 3, 78],\n",
              " [1, 198, 65, 199, 10, 3, 78, 2],\n",
              " [1, 198, 65, 199, 10, 3, 78, 2, 16],\n",
              " [1, 198, 65, 199, 10, 3, 78, 2, 16, 17],\n",
              " [1, 198, 65, 199, 10, 3, 78, 2, 16, 17, 8],\n",
              " [1, 198, 65, 199, 10, 3, 78, 2, 16, 17, 8, 200],\n",
              " [1, 198, 65, 199, 10, 3, 78, 2, 16, 17, 8, 200, 21],\n",
              " [22, 44],\n",
              " [22, 44, 201],\n",
              " [22, 44, 201, 1],\n",
              " [22, 44, 201, 1, 202],\n",
              " [22, 44, 201, 1, 202, 203],\n",
              " [22, 44, 201, 1, 202, 203, 79],\n",
              " [22, 44, 201, 1, 202, 203, 79, 6],\n",
              " [22, 44, 201, 1, 202, 203, 79, 6, 204],\n",
              " [1, 205],\n",
              " [1, 205, 80],\n",
              " [1, 205, 80, 6],\n",
              " [1, 205, 80, 6, 206],\n",
              " [1, 205, 80, 6, 206, 2],\n",
              " [1, 205, 80, 6, 206, 2, 207],\n",
              " [3, 208],\n",
              " [3, 208, 2],\n",
              " [3, 208, 2, 209],\n",
              " [3, 208, 2, 209, 12],\n",
              " [3, 208, 2, 209, 12, 81],\n",
              " [3, 208, 2, 209, 12, 81, 5],\n",
              " [3, 208, 2, 209, 12, 81, 5, 210],\n",
              " [1, 211],\n",
              " [1, 211, 56],\n",
              " [1, 211, 56, 212],\n",
              " [1, 211, 56, 212, 69],\n",
              " [1, 211, 56, 212, 69, 213],\n",
              " [1, 211, 56, 212, 69, 213, 8],\n",
              " [1, 211, 56, 212, 69, 213, 8, 5],\n",
              " [22, 39],\n",
              " [22, 39, 72],\n",
              " [22, 39, 72, 45],\n",
              " [22, 39, 72, 45, 82],\n",
              " [22, 39, 72, 45, 82, 1],\n",
              " [22, 39, 72, 45, 82, 1, 40],\n",
              " [22, 39, 72, 45, 82, 1, 40, 214],\n",
              " [1, 4],\n",
              " [1, 4, 12],\n",
              " [1, 4, 12, 19],\n",
              " [1, 4, 12, 19, 37],\n",
              " [1, 4, 12, 19, 37, 215],\n",
              " [1, 4, 12, 19, 37, 215, 10],\n",
              " [1, 4, 12, 19, 37, 215, 10, 216],\n",
              " [1, 4, 12, 19, 37, 215, 10, 216, 217],\n",
              " [1, 4, 12, 19, 37, 215, 10, 216, 217, 9],\n",
              " [1, 4, 12, 19, 37, 215, 10, 216, 217, 9, 218],\n",
              " [1, 16],\n",
              " [1, 16, 18],\n",
              " [1, 16, 18, 6],\n",
              " [1, 16, 18, 6, 3],\n",
              " [1, 16, 18, 6, 3, 219],\n",
              " [1, 16, 18, 6, 3, 219, 19],\n",
              " [1, 16, 18, 6, 3, 219, 19, 83],\n",
              " [1, 16, 18, 6, 3, 219, 19, 83, 220],\n",
              " [1, 84],\n",
              " [1, 84, 5],\n",
              " [1, 84, 5, 6],\n",
              " [1, 84, 5, 6, 3],\n",
              " [1, 84, 5, 6, 3, 85],\n",
              " [1, 84, 5, 6, 3, 85, 2],\n",
              " [1, 84, 5, 6, 3, 85, 2, 221],\n",
              " [1, 41],\n",
              " [1, 41, 222],\n",
              " [1, 41, 222, 223],\n",
              " [1, 41, 222, 223, 39],\n",
              " [1, 41, 222, 223, 39, 60],\n",
              " [1, 41, 222, 223, 39, 60, 224],\n",
              " [1, 225],\n",
              " [1, 225, 226],\n",
              " [1, 225, 226, 2],\n",
              " [1, 225, 226, 2, 227],\n",
              " [1, 225, 226, 2, 227, 228],\n",
              " [1, 229],\n",
              " [1, 229, 13],\n",
              " [1, 229, 13, 230],\n",
              " [1, 229, 13, 230, 22],\n",
              " [1, 229, 13, 230, 22, 231],\n",
              " [1, 229, 13, 230, 22, 231, 86],\n",
              " [3, 232],\n",
              " [3, 232, 4],\n",
              " [3, 232, 4, 87],\n",
              " [3, 232, 4, 87, 233],\n",
              " [3, 232, 4, 87, 233, 74],\n",
              " [3, 232, 4, 87, 233, 74, 234],\n",
              " [1, 41],\n",
              " [1, 41, 235],\n",
              " [1, 41, 235, 82],\n",
              " [1, 41, 235, 82, 42],\n",
              " [1, 41, 235, 82, 42, 7],\n",
              " [1, 41, 235, 82, 42, 7, 68],\n",
              " [1, 41, 235, 82, 42, 7, 68, 57],\n",
              " [236, 3],\n",
              " [236, 3, 237],\n",
              " [236, 3, 237, 1],\n",
              " [236, 3, 237, 1, 40],\n",
              " [236, 3, 237, 1, 40, 238],\n",
              " [1, 239],\n",
              " [1, 239, 13],\n",
              " [1, 239, 13, 240],\n",
              " [1, 239, 13, 240, 241],\n",
              " [1, 239, 13, 240, 241, 2],\n",
              " [1, 239, 13, 240, 241, 2, 75],\n",
              " [1, 239, 13, 240, 241, 2, 75, 242],\n",
              " [1, 239, 13, 240, 241, 2, 75, 242, 3],\n",
              " [1, 239, 13, 240, 241, 2, 75, 242, 3, 243],\n",
              " [1, 4],\n",
              " [1, 4, 31],\n",
              " [1, 4, 31, 20],\n",
              " [1, 4, 31, 20, 85],\n",
              " [1, 4, 31, 20, 85, 2],\n",
              " [1, 4, 31, 20, 85, 2, 88],\n",
              " [1, 4, 31, 20, 85, 2, 88, 89],\n",
              " [1, 4, 31, 20, 85, 2, 88, 89, 8],\n",
              " [1, 4, 31, 20, 85, 2, 88, 89, 8, 24],\n",
              " [1, 4, 31, 20, 85, 2, 88, 89, 8, 24, 1],\n",
              " [1, 4, 31, 20, 85, 2, 88, 89, 8, 24, 1, 14],\n",
              " [1, 15],\n",
              " [1, 15, 244],\n",
              " [1, 15, 244, 2],\n",
              " [1, 15, 244, 2, 245],\n",
              " [1, 15, 244, 2, 245, 2],\n",
              " [1, 15, 244, 2, 245, 2, 246],\n",
              " [1, 15, 244, 2, 245, 2, 246, 28],\n",
              " [1, 15, 244, 2, 245, 2, 246, 28, 21],\n",
              " [1, 15, 244, 2, 245, 2, 246, 28, 21, 6],\n",
              " [1, 15, 244, 2, 245, 2, 246, 28, 21, 6, 247],\n",
              " [1, 248],\n",
              " [1, 248, 249],\n",
              " [1, 248, 249, 2],\n",
              " [1, 248, 249, 2, 250],\n",
              " [1, 248, 249, 2, 250, 5],\n",
              " [1, 248, 249, 2, 250, 5, 6],\n",
              " [1, 248, 249, 2, 250, 5, 6, 35],\n",
              " [1, 248, 249, 2, 250, 5, 6, 35, 86],\n",
              " [1, 4],\n",
              " [1, 4, 23],\n",
              " [1, 4, 23, 2],\n",
              " [1, 4, 23, 2, 90],\n",
              " [1, 4, 23, 2, 90, 251],\n",
              " [1, 4, 23, 2, 90, 251, 8],\n",
              " [1, 4, 23, 2, 90, 251, 8, 91],\n",
              " [1, 4, 23, 2, 90, 251, 8, 91, 252],\n",
              " [1, 4, 23, 2, 90, 251, 8, 91, 252, 253],\n",
              " [1, 254],\n",
              " [1, 254, 255],\n",
              " [1, 254, 255, 256],\n",
              " [1, 254, 255, 256, 59],\n",
              " [1, 254, 255, 256, 59, 66],\n",
              " [1, 92],\n",
              " [1, 92, 257],\n",
              " [1, 92, 257, 32],\n",
              " [1, 92, 257, 32, 47],\n",
              " [1, 92, 257, 32, 47, 258],\n",
              " [1, 92, 257, 32, 47, 258, 259],\n",
              " [1, 92, 257, 32, 47, 258, 259, 2],\n",
              " [1, 92, 257, 32, 47, 258, 259, 2, 260],\n",
              " [1, 93],\n",
              " [1, 93, 5],\n",
              " [1, 93, 5, 6],\n",
              " [1, 93, 5, 6, 261],\n",
              " [1, 93, 5, 6, 261, 42],\n",
              " [1, 93, 5, 6, 261, 42, 262],\n",
              " [1, 58],\n",
              " [1, 58, 263],\n",
              " [1, 58, 263, 20],\n",
              " [1, 58, 263, 20, 3],\n",
              " [1, 58, 263, 20, 3, 264],\n",
              " [1, 58, 263, 20, 3, 264, 265],\n",
              " [1, 58, 263, 20, 3, 264, 265, 25],\n",
              " [1, 58, 263, 20, 3, 264, 265, 25, 48],\n",
              " [1, 58, 263, 20, 3, 264, 265, 25, 48, 2],\n",
              " [1, 58, 263, 20, 3, 264, 265, 25, 48, 2, 266],\n",
              " [1, 267],\n",
              " [1, 267, 3],\n",
              " [1, 267, 3, 71],\n",
              " [1, 267, 3, 71, 7],\n",
              " [1, 267, 3, 71, 7, 63],\n",
              " [1, 267, 3, 71, 7, 63, 268],\n",
              " [1, 267, 3, 71, 7, 63, 268, 1],\n",
              " [1, 267, 3, 71, 7, 63, 268, 1, 41],\n",
              " [1, 269],\n",
              " [1, 269, 27],\n",
              " [1, 269, 27, 270],\n",
              " [1, 269, 27, 270, 271],\n",
              " [1, 269, 27, 270, 271, 2],\n",
              " [1, 269, 27, 270, 271, 2, 33],\n",
              " [1, 269, 27, 270, 271, 2, 33, 38],\n",
              " [1, 269, 27, 270, 271, 2, 33, 38, 272],\n",
              " [1, 273],\n",
              " [1, 273, 274],\n",
              " [1, 273, 274, 2],\n",
              " [1, 273, 274, 2, 275],\n",
              " [1, 276],\n",
              " [1, 276, 5],\n",
              " [1, 276, 5, 39],\n",
              " [1, 276, 5, 39, 277],\n",
              " [1, 276, 5, 39, 277, 94],\n",
              " [1, 276, 5, 39, 277, 94, 2],\n",
              " [1, 276, 5, 39, 277, 94, 2, 93],\n",
              " [1, 276, 5, 39, 277, 94, 2, 93, 5],\n",
              " [1, 276, 5, 39, 277, 94, 2, 93, 5, 95],\n",
              " [1, 276, 5, 39, 277, 94, 2, 93, 5, 95, 96],\n",
              " [278, 279],\n",
              " [278, 279, 280],\n",
              " [278, 279, 280, 28],\n",
              " [278, 279, 280, 28, 34],\n",
              " [278, 279, 280, 28, 34, 36],\n",
              " [278, 279, 280, 28, 34, 36, 2],\n",
              " [278, 279, 280, 28, 34, 36, 2, 281],\n",
              " [278, 279, 280, 28, 34, 36, 2, 281, 10],\n",
              " [278, 279, 280, 28, 34, 36, 2, 281, 10, 30],\n",
              " [278, 279, 280, 28, 34, 36, 2, 281, 10, 30, 78],\n",
              " [1, 282],\n",
              " [1, 282, 283],\n",
              " [1, 282, 283, 284],\n",
              " [1, 282, 283, 284, 2],\n",
              " [1, 282, 283, 284, 2, 53],\n",
              " [1, 282, 283, 284, 2, 53, 77],\n",
              " [1, 282, 283, 284, 2, 53, 77, 10],\n",
              " [1, 282, 283, 284, 2, 53, 77, 10, 285],\n",
              " [3, 286],\n",
              " [3, 286, 33],\n",
              " [3, 286, 33, 80],\n",
              " [3, 286, 33, 80, 95],\n",
              " [3, 286, 33, 80, 95, 287],\n",
              " [3, 286, 33, 80, 95, 287, 97],\n",
              " [3, 286, 33, 80, 95, 287, 97, 3],\n",
              " [1, 54],\n",
              " [1, 54, 288],\n",
              " [1, 54, 288, 7],\n",
              " [1, 54, 288, 7, 83],\n",
              " [1, 54, 288, 7, 83, 289],\n",
              " [1, 15],\n",
              " [1, 15, 87],\n",
              " [1, 15, 87, 290],\n",
              " [1, 15, 87, 290, 291],\n",
              " [1, 15, 87, 290, 291, 292],\n",
              " [1, 15, 87, 290, 291, 292, 293],\n",
              " [1, 15, 87, 290, 291, 292, 293, 294],\n",
              " [1, 295],\n",
              " [1, 295, 3],\n",
              " [1, 295, 3, 296],\n",
              " [1, 295, 3, 296, 6],\n",
              " [1, 295, 3, 296, 6, 9],\n",
              " [1, 295, 3, 296, 6, 9, 35],\n",
              " [1, 295, 3, 296, 6, 9, 35, 76],\n",
              " [1, 98],\n",
              " [1, 98, 34],\n",
              " [1, 98, 34, 64],\n",
              " [1, 98, 34, 64, 2],\n",
              " [1, 98, 34, 64, 2, 297],\n",
              " [1, 98, 34, 64, 2, 297, 298],\n",
              " [1, 98, 34, 64, 2, 297, 298, 8],\n",
              " [1, 98, 34, 64, 2, 297, 298, 8, 32],\n",
              " [1, 98, 34, 64, 2, 297, 298, 8, 32, 299],\n",
              " [22, 6],\n",
              " [22, 6, 55],\n",
              " [22, 6, 55, 300],\n",
              " [22, 6, 55, 300, 1],\n",
              " [22, 6, 55, 300, 1, 301],\n",
              " [22, 6, 55, 300, 1, 301, 94],\n",
              " [22, 6, 55, 300, 1, 301, 94, 8],\n",
              " [22, 6, 55, 300, 1, 301, 94, 8, 302],\n",
              " [1, 92],\n",
              " [1, 92, 23],\n",
              " [1, 92, 23, 61],\n",
              " [1, 92, 23, 61, 2],\n",
              " [1, 92, 23, 61, 2, 303],\n",
              " [1, 92, 23, 61, 2, 303, 304],\n",
              " [1, 40],\n",
              " [1, 40, 305],\n",
              " [1, 40, 305, 8],\n",
              " [1, 40, 305, 8, 3],\n",
              " [1, 40, 305, 8, 3, 98],\n",
              " [1, 40, 305, 8, 3, 98, 2],\n",
              " [1, 40, 305, 8, 3, 98, 2, 306],\n",
              " [1, 4],\n",
              " [1, 4, 307],\n",
              " [1, 4, 307, 10],\n",
              " [1, 4, 307, 10, 52],\n",
              " [1, 4, 307, 10, 52, 30],\n",
              " [1, 4, 307, 10, 52, 30, 25],\n",
              " [1, 4, 307, 10, 52, 30, 25, 38],\n",
              " [1, 4, 307, 10, 52, 30, 25, 38, 7],\n",
              " [1, 4, 307, 10, 52, 30, 25, 38, 7, 99],\n",
              " [1, 84],\n",
              " [1, 84, 5],\n",
              " [1, 84, 5, 8],\n",
              " [1, 84, 5, 8, 91],\n",
              " [1, 84, 5, 8, 91, 9],\n",
              " [1, 84, 5, 8, 91, 9, 96],\n",
              " [1, 84, 5, 8, 91, 9, 96, 2],\n",
              " [1, 84, 5, 8, 91, 9, 96, 2, 308],\n",
              " [1, 84, 5, 8, 91, 9, 96, 2, 308, 309],\n",
              " [1, 84, 5, 8, 91, 9, 96, 2, 308, 309, 310],\n",
              " [1, 26],\n",
              " [1, 26, 3],\n",
              " [1, 26, 3, 311],\n",
              " [1, 26, 3, 311, 312],\n",
              " [1, 26, 3, 311, 312, 2],\n",
              " [1, 26, 3, 311, 312, 2, 313],\n",
              " [1, 26, 3, 311, 312, 2, 313, 21],\n",
              " [1, 26, 3, 311, 312, 2, 313, 21, 6],\n",
              " [1, 26, 3, 311, 312, 2, 313, 21, 6, 89],\n",
              " [1, 314],\n",
              " [1, 314, 315],\n",
              " [1, 314, 315, 8],\n",
              " [1, 314, 315, 8, 24],\n",
              " [1, 314, 315, 8, 24, 1],\n",
              " [1, 314, 315, 8, 24, 1, 14],\n",
              " [1, 316],\n",
              " [1, 316, 42],\n",
              " [1, 316, 42, 317],\n",
              " [1, 316, 42, 317, 2],\n",
              " [1, 316, 42, 317, 2, 90],\n",
              " [1, 316, 42, 317, 2, 90, 50],\n",
              " [1, 316, 42, 317, 2, 90, 50, 79],\n",
              " [3, 318],\n",
              " [3, 318, 319],\n",
              " [3, 318, 319, 88],\n",
              " [3, 318, 319, 88, 320],\n",
              " [3, 318, 319, 88, 320, 8],\n",
              " [3, 318, 319, 88, 320, 8, 73],\n",
              " [3, 318, 319, 88, 320, 8, 73, 97],\n",
              " [3, 318, 319, 88, 320, 8, 73, 97, 3],\n",
              " [1, 36],\n",
              " [1, 36, 321],\n",
              " [1, 36, 321, 2],\n",
              " [1, 36, 321, 2, 16],\n",
              " [1, 36, 321, 2, 16, 17],\n",
              " [1, 36, 321, 2, 16, 17, 8],\n",
              " [1, 36, 321, 2, 16, 17, 8, 81],\n",
              " [1, 36, 321, 2, 16, 17, 8, 81, 21],\n",
              " [1, 36, 321, 2, 16, 17, 8, 81, 21, 322],\n",
              " [3, 323],\n",
              " [3, 323, 324],\n",
              " [3, 323, 324, 13],\n",
              " [3, 323, 324, 13, 99],\n",
              " [3, 323, 324, 13, 99, 6],\n",
              " [3, 323, 324, 13, 99, 6, 29],\n",
              " [3, 323, 324, 13, 99, 6, 29, 67],\n",
              " [3, 323, 324, 13, 99, 6, 29, 67, 2],\n",
              " [3, 323, 324, 13, 99, 6, 29, 67, 2, 325]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "CrzbvUUQCXPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy0CADxp76WS",
        "outputId": "260444d9-8363-4410-953d-841977f0e2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "9oPMoWBSD1_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRb-QZyIi7_",
        "outputId": "5ede9961-e1a1-4def-9670-83317b0fc355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  9, 42],\n",
              "       [ 0,  0,  0, ...,  9, 42, 10],\n",
              "       [ 0,  0,  0, ..., 42, 10,  6],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  2, 41, 12],\n",
              "       [ 0,  0,  0, ..., 41, 12,  1],\n",
              "       [ 0,  0,  0, ..., 12,  1, 36]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "qVI0-UUrIsd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "lXrYHTDFI3uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmsFnHx1Qdow",
        "outputId": "453e5bd5-89e8-497f-eba8-7248898e7fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyYqYgZSeck",
        "outputId": "5f4caca7-d2d6-473d-b268-b0c0f1925cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OL3vrEXSs_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=138)"
      ],
      "metadata": {
        "id": "rs1NPitwSgzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMJ0I6xSiZf",
        "outputId": "f130d049-1f5b-4a3d-d78b-a627852a211a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 138)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "9kVeTvR2S8Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 1) Single Embedding layer at the bottom\n",
        "model.add(Embedding(input_dim=138, output_dim=70, input_length=13))\n",
        "\n",
        "# 2) First LSTM: return_sequences=True so it emits a full sequence\n",
        "model.add(LSTM(250, return_sequences=True))\n",
        "\n",
        "# 3) Second LSTM: now consumes the sequence output\n",
        "model.add(LSTM(150))       # return_sequences defaults to False here\n",
        "\n",
        "# 4) Final classification layer\n",
        "model.add(Dense(138, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "wo-OYfHpTK2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-GGjqh7ue_Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "OxxXkrSXfIBv",
        "outputId": "e7010cd7-901a-4123-a89e-5971e3ab0a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFUCALCfJRR",
        "outputId": "7e2ff3e8-078b-408c-d9b0-85101c1e210d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.0910 - loss: 4.9152\n",
            "Epoch 2/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1402 - loss: 4.6454\n",
            "Epoch 3/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.1249 - loss: 4.3933\n",
            "Epoch 4/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1114 - loss: 4.3885\n",
            "Epoch 5/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1146 - loss: 4.3266\n",
            "Epoch 6/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.1043 - loss: 4.4063\n",
            "Epoch 7/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1062 - loss: 4.3168\n",
            "Epoch 8/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1356 - loss: 4.2435\n",
            "Epoch 9/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1536 - loss: 4.1350\n",
            "Epoch 10/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1359 - loss: 4.1968\n",
            "Epoch 11/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.1353 - loss: 4.2103\n",
            "Epoch 12/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.1587 - loss: 4.0489\n",
            "Epoch 13/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.1585 - loss: 3.9845\n",
            "Epoch 14/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.1625 - loss: 3.8114\n",
            "Epoch 15/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1646 - loss: 3.7938\n",
            "Epoch 16/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1946 - loss: 3.6575\n",
            "Epoch 17/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1651 - loss: 3.6461\n",
            "Epoch 18/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1979 - loss: 3.4764\n",
            "Epoch 19/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2034 - loss: 3.3493\n",
            "Epoch 20/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.1866 - loss: 3.4423\n",
            "Epoch 21/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.2126 - loss: 3.3674\n",
            "Epoch 22/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2349 - loss: 3.3222\n",
            "Epoch 23/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1809 - loss: 3.3670\n",
            "Epoch 24/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.2291 - loss: 3.1786\n",
            "Epoch 25/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2487 - loss: 3.0712\n",
            "Epoch 26/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.2157 - loss: 3.0748\n",
            "Epoch 27/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2813 - loss: 2.8729\n",
            "Epoch 28/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.2787 - loss: 2.8283\n",
            "Epoch 29/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.2453 - loss: 2.8608\n",
            "Epoch 30/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.2925 - loss: 2.7270\n",
            "Epoch 31/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.2826 - loss: 2.7112\n",
            "Epoch 32/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.2821 - loss: 2.6263\n",
            "Epoch 33/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2671 - loss: 2.6597\n",
            "Epoch 34/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.3620 - loss: 2.4201\n",
            "Epoch 35/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.4105 - loss: 2.3411\n",
            "Epoch 36/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.4302 - loss: 2.2469\n",
            "Epoch 37/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4106 - loss: 2.3476\n",
            "Epoch 38/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.3486 - loss: 2.4091\n",
            "Epoch 39/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.4105 - loss: 2.2365\n",
            "Epoch 40/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4531 - loss: 2.0805\n",
            "Epoch 41/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.4750 - loss: 2.0848\n",
            "Epoch 42/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4706 - loss: 2.0524\n",
            "Epoch 43/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5171 - loss: 1.9953\n",
            "Epoch 44/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5197 - loss: 1.9110\n",
            "Epoch 45/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.4760 - loss: 1.9696\n",
            "Epoch 46/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5284 - loss: 1.8761\n",
            "Epoch 47/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.4960 - loss: 1.8569\n",
            "Epoch 48/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5769 - loss: 1.8106\n",
            "Epoch 49/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.5764 - loss: 1.7516\n",
            "Epoch 50/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5748 - loss: 1.6966\n",
            "Epoch 51/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5943 - loss: 1.6485\n",
            "Epoch 52/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.5731 - loss: 1.6605\n",
            "Epoch 53/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6239 - loss: 1.5702\n",
            "Epoch 54/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5609 - loss: 1.5603\n",
            "Epoch 55/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6124 - loss: 1.5173\n",
            "Epoch 56/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6093 - loss: 1.4944\n",
            "Epoch 57/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6265 - loss: 1.4065\n",
            "Epoch 58/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6670 - loss: 1.3553\n",
            "Epoch 59/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.6215 - loss: 1.3570\n",
            "Epoch 60/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6918 - loss: 1.2551\n",
            "Epoch 61/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6485 - loss: 1.3285\n",
            "Epoch 62/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6371 - loss: 1.3027\n",
            "Epoch 63/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6614 - loss: 1.2590\n",
            "Epoch 64/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6742 - loss: 1.2416\n",
            "Epoch 65/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.7345 - loss: 1.1101\n",
            "Epoch 66/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.6834 - loss: 1.2052\n",
            "Epoch 67/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6886 - loss: 1.1599\n",
            "Epoch 68/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7320 - loss: 1.1318\n",
            "Epoch 69/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7292 - loss: 1.0850\n",
            "Epoch 70/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7351 - loss: 1.0488\n",
            "Epoch 71/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7251 - loss: 1.0456\n",
            "Epoch 72/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7741 - loss: 0.9581\n",
            "Epoch 73/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7361 - loss: 1.0215\n",
            "Epoch 74/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7354 - loss: 0.9917\n",
            "Epoch 75/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7646 - loss: 0.9513\n",
            "Epoch 76/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7497 - loss: 0.9807\n",
            "Epoch 77/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7033 - loss: 1.0205\n",
            "Epoch 78/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7667 - loss: 0.8723\n",
            "Epoch 79/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7541 - loss: 0.8665\n",
            "Epoch 80/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7500 - loss: 0.9163\n",
            "Epoch 81/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7559 - loss: 0.8521\n",
            "Epoch 82/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7760 - loss: 0.8052\n",
            "Epoch 83/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7728 - loss: 0.7913\n",
            "Epoch 84/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7619 - loss: 0.8288\n",
            "Epoch 85/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7824 - loss: 0.8020\n",
            "Epoch 86/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7460 - loss: 0.8473\n",
            "Epoch 87/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7930 - loss: 0.7877\n",
            "Epoch 88/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7824 - loss: 0.7876\n",
            "Epoch 89/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7796 - loss: 0.7266\n",
            "Epoch 90/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7730 - loss: 0.7292\n",
            "Epoch 91/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8007 - loss: 0.6696\n",
            "Epoch 92/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7560 - loss: 0.7552\n",
            "Epoch 93/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7913 - loss: 0.6986\n",
            "Epoch 94/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7519 - loss: 0.7080\n",
            "Epoch 95/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7657 - loss: 0.7453\n",
            "Epoch 96/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7646 - loss: 0.7166\n",
            "Epoch 97/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8189 - loss: 0.6632\n",
            "Epoch 98/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8003 - loss: 0.6449\n",
            "Epoch 99/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.7960 - loss: 0.6740\n",
            "Epoch 100/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7657 - loss: 0.6911\n",
            "Epoch 101/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7876 - loss: 0.6356\n",
            "Epoch 102/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8093 - loss: 0.6256\n",
            "Epoch 103/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7678 - loss: 0.6539\n",
            "Epoch 104/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8016 - loss: 0.6178\n",
            "Epoch 105/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7879 - loss: 0.6317\n",
            "Epoch 106/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7746 - loss: 0.5935\n",
            "Epoch 107/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7913 - loss: 0.6006\n",
            "Epoch 108/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7857 - loss: 0.6104\n",
            "Epoch 109/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7608 - loss: 0.6208\n",
            "Epoch 110/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7841 - loss: 0.5877\n",
            "Epoch 111/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7523 - loss: 0.6394\n",
            "Epoch 112/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8009 - loss: 0.5502\n",
            "Epoch 113/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7939 - loss: 0.5759\n",
            "Epoch 114/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8158 - loss: 0.5309\n",
            "Epoch 115/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7416 - loss: 0.6033\n",
            "Epoch 116/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.8055 - loss: 0.5413\n",
            "Epoch 117/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8079 - loss: 0.5363\n",
            "Epoch 118/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.7999 - loss: 0.5333\n",
            "Epoch 119/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.8189 - loss: 0.5029\n",
            "Epoch 120/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7935 - loss: 0.5265\n",
            "Epoch 121/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8046 - loss: 0.4992\n",
            "Epoch 122/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7844 - loss: 0.5322\n",
            "Epoch 123/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8145 - loss: 0.4885\n",
            "Epoch 124/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8078 - loss: 0.4952\n",
            "Epoch 125/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7753 - loss: 0.5661\n",
            "Epoch 126/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7968 - loss: 0.5184\n",
            "Epoch 127/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7953 - loss: 0.5151\n",
            "Epoch 128/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7892 - loss: 0.5008\n",
            "Epoch 129/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7833 - loss: 0.5280\n",
            "Epoch 130/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7668 - loss: 0.5323\n",
            "Epoch 131/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7685 - loss: 0.5268\n",
            "Epoch 132/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7837 - loss: 0.5063\n",
            "Epoch 133/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8127 - loss: 0.4735\n",
            "Epoch 134/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8177 - loss: 0.4738\n",
            "Epoch 135/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7811 - loss: 0.5057\n",
            "Epoch 136/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7709 - loss: 0.4998\n",
            "Epoch 137/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.8236 - loss: 0.4786\n",
            "Epoch 138/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.7940 - loss: 0.4937\n",
            "Epoch 139/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7787 - loss: 0.4826\n",
            "Epoch 140/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7938 - loss: 0.4828\n",
            "Epoch 141/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7859 - loss: 0.4777\n",
            "Epoch 142/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8475 - loss: 0.4099\n",
            "Epoch 143/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8028 - loss: 0.4689\n",
            "Epoch 144/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7987 - loss: 0.4484\n",
            "Epoch 145/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8160 - loss: 0.4357\n",
            "Epoch 146/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7623 - loss: 0.5231\n",
            "Epoch 147/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8133 - loss: 0.4526\n",
            "Epoch 148/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7981 - loss: 0.4821\n",
            "Epoch 149/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7658 - loss: 0.4858\n",
            "Epoch 150/150\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7995 - loss: 0.4707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78714c521590>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "OO2tEX3fx3QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "def next_predictions(text):\n",
        "    for i in range(3):\n",
        "        token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "        padded = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "        pos = np.argmax(model.predict(padded), axis=-1)[0]\n",
        "\n",
        "        # find the word with that index\n",
        "        for word, idx in tokenizer.word_index.items():\n",
        "            if idx == pos:\n",
        "                text += \" \" + word\n",
        "                break  # stop scanning once we've found it\n",
        "\n",
        "    # Now print the final text with a delay between each word\n",
        "    for w in text.split():\n",
        "        print(w, end=' ', flush=True)\n",
        "        time.sleep(1)\n",
        "    print()  # Final newline\n"
      ],
      "metadata": {
        "id": "PxkepqW0-22L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I miss\"\n",
        "next_predictions(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fSKTiL2E7ZDj",
        "outputId": "2651a1c4-7684-4a37-d352-3fbd389b215d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "I miss you \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"how\"\n",
        "next_predictions(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEBWlcAK9Qn7",
        "outputId": "b53ade4b-c513-400f-fd1f-be3e3bc49fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "how are you meet \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QP1ZQa_57di6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TfN3E_Bj_uxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zxRI5Hc5_uuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6KYQr9q5_urb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0obgISAw_uet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oKbK4j7B_ubR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5wrZn2-l_uY0"
      }
    }
  ]
}